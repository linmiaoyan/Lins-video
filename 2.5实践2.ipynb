{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import wave\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 核心函数：音频处理函数\n",
    "\n",
    "在上一个图像识别的案例中，我们使用CV2和PIL库处理图片，现在，我们使用wave库处理音频文件。\n",
    "\n",
    "get_wavedata函数能够读取音频文件，并转为我们需要的格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wavedata(wav_path):\n",
    "    f = wave.open(wav_path,'rb')\n",
    "    params = f.getparams()\n",
    "    nchannels, sampwidth, framerate, nframes = params[:4]\n",
    "    #读取音频，转换成int格式\n",
    "    strData = f.readframes(nframes)\n",
    "    waveData = np.fromstring(strData,dtype=np.int16)\n",
    "    #数据归一化\n",
    "    waveData = waveData*1.0/(max(abs(waveData)))\n",
    "    waveData = np.reshape(waveData,[nframes,nchannels]).T\n",
    "    f.close()\n",
    "    # 处理音频时长\n",
    "    data = list(np.array(waveData[0]))\n",
    "    while len(data)>16000:\n",
    "        del data[len(waveData[0])-1]\n",
    "        del data[0]\n",
    "    while len(data)<16000:\n",
    "        data.append(0)\n",
    "    data=np.array(data)\n",
    "    # 平方之后，开平方，取正数，值的范围在  0-1  之间\n",
    "    data = (data ** 2)** 0.5\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理\n",
    "\n",
    "加载数据集和标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始加载: 0zero\n",
      "开始加载: 1one\n",
      "(13, 16000)\n",
      "(13, 2)\n",
      "(2, 16000)\n",
      "(2, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\application\\python\\lib\\site-packages\\ipykernel\\__main__.py:7: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
     ]
    }
   ],
   "source": [
    "num_class = 0 # 存放语音总类别的数量\n",
    "labsIndName=[]      # 训练集标签的名字   \n",
    "wavs=[] # 训练wav文件集\n",
    "labels=[] # labels 和 testlabels 这里面存的值都是对应标签的下标，下标对应的名字在labsInd中\n",
    "testwavs=[] # 测试wav文件集\n",
    "testlabels=[] # 测试集标签\n",
    "percent=10   #抽取作测试集的比例，10为抽取10%文件作为测试集\n",
    "\n",
    "path=\"data\"\n",
    "dirs = os.listdir(path) # 获取的是目录列表\n",
    "for i in dirs:\n",
    "    print(\"开始加载:\",i)\n",
    "    labsIndName.append(i) # 当前分类进入到标签的名字集\n",
    "    wavs_path=path+\"\\\\\"+i\n",
    "    testNum=0 #  目前文件夹中进入了测试集的数量\n",
    "    files = os.listdir(wavs_path) # 某个目录下文件的列表\n",
    "    #直接用代码区分数据，从文件夹中抽取一定量的文件作为训练集和测试集\n",
    "    for j in files:\n",
    "        try:\n",
    "            waveData = get_wavedata(wavs_path+\"\\\\\"+j)\n",
    "            if testNum < (len(files)/percent) :     #每个文件夹中抽出percent%作为测试集  \n",
    "                testwavs.append(waveData)\n",
    "                testlabels.append(labsIndName.index(i))\n",
    "                testNum+=1\n",
    "            else:\n",
    "                wavs.append(waveData)\n",
    "                labels.append(labsIndName.index(i))\n",
    "        except:\n",
    "            pass\n",
    "num_class = len(labsIndName)\n",
    "\n",
    "wavs=np.array(wavs)\n",
    "labels=np.array(labels)\n",
    "testwavs=np.array(testwavs)\n",
    "testlabels=np.array(testlabels)\n",
    "\n",
    "# 标签转换为独热码\n",
    "labels = keras.utils.to_categorical(labels, num_class)\n",
    "testlabels = keras.utils.to_categorical(testlabels, num_class)\n",
    "\n",
    "print(wavs.shape)\n",
    "print(labels.shape)\n",
    "print(testwavs.shape)\n",
    "print(testlabels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu',input_shape=(16000,)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_class, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将识别准确率作为模型评估标准\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "model.fit(wavs, labels, batch_size=100, epochs=20, verbose=2, validation_data=(testwavs, testlabels))\n",
    "\n",
    "# 评估模型效果\n",
    "score = model.evaluate(testwavs, testlabels, verbose=2)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1]) \n",
    "\n",
    "model.save('0to9_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 应用模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import load_model\n",
    "wavs=[]\n",
    "\n",
    "# 加载模型\n",
    "model = load_model('0to9_model.h5') # 加载训练模型\n",
    "\n",
    "wavs.append(get_wavedata(\"testdata/test.wav\"))\n",
    "X=np.array(wavs)\n",
    "print(X.shape)\n",
    "result=model.predict(X[0:1])[0] \n",
    "print(\"识别结果\",result)\n",
    "#标签集的名字\n",
    "name = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"] # 创建一个跟训练时一样的标签集\n",
    "ind=0 # 结果中最大的一个数\n",
    "for i in range(len(result)):\n",
    "    if result[i] > result[ind]:\n",
    "        ind=i\n",
    "print(\"识别的语音结果是：\",name[ind])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VPython",
   "language": "python",
   "name": "vpython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
